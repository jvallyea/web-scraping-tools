{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pandarallel import pandarallel\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# Reads a stored CSV of pname, LI, company name, website\n",
    "df = pd.read_csv('webTitles.csv')\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method to extract a website title given a website string of the form: http://***\n",
    "    @param: website: a String for a website to search\n",
    "    @return: a String for the title text for the website\n",
    "'''\n",
    "def getWebsiteTitle(website):\n",
    "    # Check to make sure website starts with http\n",
    "    if website[:4] != \"http\":\n",
    "        website = \"http://\" + website\n",
    "    # Extracts web page and returns title text if found. Timeout parameters.\n",
    "    try:\n",
    "        s_ = BeautifulSoup(requests.get(website, timeout=(1.5, 3.0)).text).title.text\n",
    "        return s_\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populates a dataframe (df) with the column 'webtitle' which represents the title text\n",
    "# for the website. Print statements are every 100 websites to keep track of progress. \n",
    "# This function is parallelized in batches of 100.\n",
    "num_buckets = df.shape[0]\n",
    "num_buckets = int(num_buckets / 100)\n",
    "for i in range(9,num_buckets):\n",
    "    print(i)\n",
    "    tm.sleep(2)\n",
    "    start = 100 * i ; end = 100 * (i+1)\n",
    "    df['webtitle'] = df['website'][start:end].parallel_apply(lambda x: getWebsiteTitle(x))\n",
    "    df[start:end].to_csv('webtitles_final.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the previous cell, we re-load the saved CSV file and drop any duplicates. \n",
    "# Then, the new file is saved and should be converted to a .xlsx file and put through\n",
    "# an online converted back to a CSV (newfile.csv). This is because some of the spacing\n",
    "# for the dataframe CSV is a bit off.\n",
    "df2 = pd.read_csv('webtitles_final.csv', names=['pname', 'LI', 'name', 'website', 'webtitle'])\n",
    "\n",
    "inds = []\n",
    "for i in range(df.shape[0]):\n",
    "    try:\n",
    "        if df2.loc[i].pname != df.loc[i].pname:\n",
    "            inds.append(i)\n",
    "    except:\n",
    "        print(i)\n",
    "        \n",
    "df2.drop_duplicates(subset=df2.columns[0:2], keep=False)\n",
    "df2.to_csv('webtitles_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the newly converted CSV (newfile.csv), columns 5-10 are condensed and re-saved.\n",
    "df = pd.read_csv('newfile.csv', names=['pname', 'LI', 'name', 'website',\n",
    "                                       'webtitle','5','6','7','8','9','10'])\n",
    "df.fillna(\"\", inplace=True)\n",
    "df[\"webtitle\"] = df[[\"webtitle\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]].agg(' '.join, axis=1)\n",
    "df = df.drop(columns=['5', '6', '7', '8', '9', '10'])\n",
    "df.to_csv('myfile.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Miniconda3",
   "language": "python",
   "name": "miniconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
