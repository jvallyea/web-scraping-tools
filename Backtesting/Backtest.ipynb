{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import csv \n",
    "from parsel import Selector\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Class to describe a given company \n",
    "    @field: name: a string for the company name\n",
    "    @field: description: a string for the company description\n",
    "    @field: founders: a list of Founder objects\n",
    "    @field: industries: a list of strings for different industries\n",
    "    @field: website: a string for the website\n",
    "    @field: lastStage: a string for the last stage of funding (eg. Series A)\n",
    "    @field: linkedin: a string for the company's LinkedIn profile\n",
    "    @field: location: a string for the company's location\n",
    "'''\n",
    "class Company:\n",
    "    def __init__(self, companyName):\n",
    "        self.name = companyName\n",
    "        self.description = None\n",
    "        self.founders = []\n",
    "        self.industries = []\n",
    "        self.website = None\n",
    "        self.lastStage = None\n",
    "        self.linkedin = None\n",
    "    \n",
    "    def toJson(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__)\n",
    "    \n",
    "'''\n",
    "Class to describe a founder\n",
    "    @field: name: a string for the founder's name\n",
    "    @field: education: an list of education objects\n",
    "    @field: experience: a list of experience objects\n",
    "'''\n",
    "class Founder:\n",
    "    def __init__(self, founderName):\n",
    "        self.name = founderName\n",
    "        self.connections = None\n",
    "        self.location = None\n",
    "        self.education = []\n",
    "        self.experience = []\n",
    "\n",
    "'''\n",
    "Class to help describe a founder's education\n",
    "    @field: degree: a string to describe the degree objective\n",
    "    @field: school: a string for the school attended\n",
    "    @field: field: a string to describe the major\n",
    "'''\n",
    "class Education:\n",
    "    def __init__(self, schoolName):\n",
    "        self.school = schoolName\n",
    "        self.degree = None\n",
    "        self.field = None\n",
    "'''\n",
    "Class to help describe a founder's experience\n",
    "    @field: companyName: a string to describe the company's name\n",
    "    @field: title: a string to describe the title held\n",
    "    @field: description: a string to describe the job description\n",
    "'''       \n",
    "class Experience:\n",
    "    def __init__(self, companyName):\n",
    "        self.companyName = companyName\n",
    "        self.title = None\n",
    "        self.dates = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Loads the dataframe from Query 1 and Query 2 and merges + drops duplicates and NaNs\n",
    "    @param: csv1: path to CSV 1 (formed by Query 1)\n",
    "    @param: csv2: path to CSV 2 (formed by Query 2)\n",
    "    @return: df1: a merged dataframe of csv1 and csv2\n",
    "'''\n",
    "def loadBacktestData(csv1, csv2):\n",
    "    df1 = pd.read_csv(csv1)\n",
    "    df2 = pd.read_csv(csv2)\n",
    "    df1 = df1.append(df2)\n",
    "    df1 = df1.drop_duplicates(subset=['Organization Name'])\n",
    "    df1 = df1[df1.Founders.notna()]\n",
    "    df1 = df1[df1.LinkedIn.notna()]\n",
    "    df1 = df1.reset_index()\n",
    "    for i in range(len(df1)):\n",
    "        if df1.iloc[i].LinkedIn.count('about') > 0:\n",
    "            df1['LinkedIn'][i] = df1['LinkedIn'][i].split('about')[0]\n",
    "    return df1\n",
    "\n",
    "# Loads and combines both CSVs into df1 dataframe\n",
    "df1 = loadBacktestData('backtest1.csv', 'backtest2.csv')\n",
    "# Creates a company_data dictionary to store scraped data\n",
    "company_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method to set up and log into the LinkedIn using chromedriver\n",
    "    @param: driverPath: path to the chromedriver.exe file\n",
    "    @param: liUsername: string of LI username\n",
    "    @param: liPassword: string of LI password\n",
    "    @return: driver: the Chrome Webdriver (can be passed into future function arguments)\n",
    "'''\n",
    "def setupDriver(driverPath, liUsername, liPassword):\n",
    "    # Sets up Chrome Webdriver and navigates to LinkedIn\n",
    "    driver = webdriver.Chrome(driverPath)\n",
    "    driver.get('https://www.linkedin.com/')\n",
    "    sleep(2.0)\n",
    "    \n",
    "    # Signs in with given credentials and returns the driver\n",
    "    driver.find_element_by_xpath('//a[text()=\"Sign in\"]').click()\n",
    "    sleep(2.0)\n",
    "    username_input = driver.find_element_by_name('session_key')\n",
    "    username_input.send_keys(liUsername)\n",
    "    password_input = driver.find_element_by_name('session_password')\n",
    "    password_input.send_keys(liPassword)\n",
    "    sleep(2.0)\n",
    "    driver.find_element_by_xpath('//button[text()=\"Sign in\"]').click()\n",
    "    return driver\n",
    "\n",
    "# Launches LinkedIn and logs in\n",
    "driver = setupDriver('./chromedriver', ' julianvallyeason@gmail.com', 'Acceleprise1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method to add LI information for a company into the company_data dictionary with a new company object\n",
    "    @param: entry: a pandas series extracted from a single row in the dataframe from loadBacktestData\n",
    "    @return: None\n",
    "This method updates the company_data dictionary and returns nothing\n",
    "'''\n",
    "def extractLIInfo(entry):\n",
    "    # Adds a new company entry to the company_data dictionary and populates fields\n",
    "    company_ = Company(entry['Organization Name'])\n",
    "    company_.description = entry['Description']\n",
    "    company_.industries = [i.strip() for i in entry['Industries'].split(',')]\n",
    "    company_.website = entry['Website']\n",
    "    company_.lastStage = entry['Last Funding Type']\n",
    "    # Edge case where the LinkedIn link does not end in '/'\n",
    "    if entry['LinkedIn'][-1] != '/':\n",
    "        entry['LinkedIn'] = entry['LinkedIn'] + '/'\n",
    "    company_.linkedin = entry['LinkedIn']\n",
    "    company_.location = entry['Headquarters Location']\n",
    "    \n",
    "    # Generates a list of founder names\n",
    "    founderNames = [i.strip() for i in entry['Founders'].split(',')]\n",
    "    # Navigates to the company's primary LinkedIn page [People Tab]\n",
    "    try:\n",
    "        driver.get(entry['LinkedIn'] + \"people/\")\n",
    "        sleep(1.0)\n",
    "        # For each founder in the list, the school name, degree, and major is extracted\n",
    "        for founder in founderNames:\n",
    "            name_input = driver.find_element_by_id('people-search-keywords')\n",
    "            name_input.send_keys(founder)\n",
    "            driver.find_element_by_id(\"people-search-keywords\").send_keys(Keys.ENTER)\n",
    "            sleep(1.0)\n",
    "            try:\n",
    "                driver.find_element_by_xpath('//a[@data-control-name = \"people_profile_card_name_link\"]').click()\n",
    "                sleep(2.0)\n",
    "                # Scrolls to the bottom of the webpage (if no scroll, error where the full webpage doens't load)\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight/2);\")\n",
    "                sleep(0.75)\n",
    "                # Creates a founder object for the given founder\n",
    "                founder_ = Founder(founder)\n",
    "\n",
    "                ###########################################################\n",
    "                # Extracts degree information (formatted as a list of items)\n",
    "                schools = driver.find_elements_by_xpath('//div[@class=\"pv-entity__degree-info\"]')\n",
    "                for school in schools:\n",
    "                    school_ = school.text.split('\\n')\n",
    "                    # The school is formatted as a list [School Name,'Degree Name',Degree Name,'Field of Study',FOS]\n",
    "                    try:\n",
    "                        educ_ = Education(school_[0])\n",
    "                        try:\n",
    "                            educ_.degree = school_[2]\n",
    "                            educ_.field = school_[4]\n",
    "                        except:\n",
    "                            pass\n",
    "                        # Appends the temporary education object to the founder\n",
    "                        founder_.education.append(educ_)\n",
    "                    except:\n",
    "                        print(\"No schools\")\n",
    "                        pass\n",
    "\n",
    "                ###############################################################    \n",
    "                # Extracts experience information (formatted as a list of items)\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight/3);\")\n",
    "                sleep(1.0)\n",
    "                experiences = driver.find_elements_by_xpath('//a[@data-control-name=\"background_details_company\"]')\n",
    "                for exp in experiences:\n",
    "                    exp_lst = exp.text.split('\\n')\n",
    "                    # The exp_ is formatted as [title, 'companyname', companyname, 'datesemployed', datesemployed, ..]\n",
    "                    try:\n",
    "                        if exp_lst[0] == 'Company Name':\n",
    "                            exp_ = Experience(exp_lst[1])\n",
    "                            founder_.experience.append(exp_)\n",
    "                        else:\n",
    "                            exp_ = Experience(exp_lst[2])\n",
    "                            try:\n",
    "                                exp_.title = exp_lst[0]\n",
    "                                exp_.dates = exp_lst[4]\n",
    "                                founder_.experience.append(exp_)\n",
    "                            except:\n",
    "                                founder_.experience.append(exp_)\n",
    "                    except:\n",
    "                        print(\"No experience\")\n",
    "                        pass\n",
    "                # Appends the temporary founder object to the company\n",
    "                company_.founders.append(founder_)\n",
    "                # Re-navigates to company's LinkedIn page\n",
    "                driver.get(entry['LinkedIn'] + \"people/\")\n",
    "                sleep(1.0)\n",
    "            except:\n",
    "                founder_ = Founder(founder)\n",
    "                company_.founders.append(founder_)\n",
    "                print(\"{} not found for {}\".format(company_.name, founder_.name))\n",
    "                driver.get(entry['LinkedIn'] + \"people/\")\n",
    "                sleep(1.0)\n",
    "    except:\n",
    "        print(\"LinkedIn page doesn't exist\")\n",
    "    # Adds the company to the company_data dictionary\n",
    "    company_data[company_.name] = company_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method to save the company data as a txt file (loadable as JSON)\n",
    "    @param: data: company_data dictionary of Company objects\n",
    "    @return: None\n",
    "'''\n",
    "def saveData(data, fileName):\n",
    "    data_json = json.dumps(data, default=lambda x: x.__dict__)\n",
    "    with open(fileName, 'w') as outfile:\n",
    "        json.dump(data_json, outfile)\n",
    "\n",
    "'''\n",
    "Method to load company data into a dictionary (same structure as Company object)\n",
    "    @param: dataFile: string path to saved txt file\n",
    "    @return: dataDict: a dictionary with the same structure as a Company object\n",
    "'''\n",
    "def loadData(dataFile):\n",
    "    with open(dataFile) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    dataDict = json.loads(data)\n",
    "    return dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########BEWARE#####\n",
    "# Stores data for a single company in company_data\n",
    "for i in range(12,100):\n",
    "    print(i)\n",
    "    if i%5 == 0:\n",
    "        sleep(5.0)\n",
    "    extractLIInfo(df1.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData(company_data, 'data100.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = loadData('data.txt')\n",
    "data2 = loadData('data2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines two dictionaries together\n",
    "z = {**data1, **data2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "THIS IS THE SLOWER VERSION - BUT WORKS BY GETTING AROUND LI USER LIMITS\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method to add LI information for a company into the company_data dictionary with a new company object\n",
    "    @param: entry: a pandas series extracted from a single row in the dataframe from loadBacktestData\n",
    "    @return: None\n",
    "This method updates the company_data dictionary and returns nothing\n",
    "'''\n",
    "def scrapeLI(entry):\n",
    "    # Adds a new company entry to the company_data dictionary and populates fields\n",
    "    company_ = Company(entry['Organization Name'])\n",
    "    company_.description = entry['Description']\n",
    "    company_.industries = [i.strip() for i in entry['Industries'].split(',')]\n",
    "    company_.website = entry['Website']\n",
    "    company_.lastStage = entry['Last Funding Type']\n",
    "    # Edge case where the LinkedIn link does not end in '/'\n",
    "    if entry['LinkedIn'][-1] != '/':\n",
    "        entry['LinkedIn'] = entry['LinkedIn'] + '/'\n",
    "    company_.linkedin = entry['LinkedIn']\n",
    "    company_.location = entry['Headquarters Location']\n",
    "    \n",
    "    # Generates a list of founder names\n",
    "    founderNames = [i.strip() for i in entry['Founders'].split(',')]\n",
    "    try:\n",
    "        # For each founder in the list, the school name, degree, and major is extracted\n",
    "        for founder in founderNames:\n",
    "            # Finds the main search bar)\n",
    "            search = driver.find_elements_by_xpath('//input[@class=\"search-global-typeahead__input always-show-placeholder\"]')\n",
    "            sleep(0.5)\n",
    "            search[0].click()\n",
    "            for i in range(50):\n",
    "                search[0].send_keys(Keys.RIGHT)\n",
    "            # Clears any existing search\n",
    "            for i in range(80):\n",
    "                search[0].send_keys(Keys.BACKSPACE)\n",
    "            # Types in founder name + company name and searches\n",
    "            search[0].send_keys(founder + \" \" + company_.name.split(\" \")[0])\n",
    "            search[0].send_keys(Keys.ENTER)\n",
    "            sleep(2.0)\n",
    "            try:\n",
    "                a = driver.find_element_by_xpath('//a[@data-control-name=\"search_srp_result\"]')\n",
    "                if a:\n",
    "                    a.click()\n",
    "                    sleep(2.0)\n",
    "                    # Scrolls to the bottom of the webpage (if no scroll, error where the full webpage doens't load)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight/2);\")\n",
    "                    sleep(0.75)\n",
    "                    # Creates a founder object for the given founder\n",
    "                    founder_ = Founder(founder)\n",
    "                   ###########################################################\n",
    "#                  #Extracts data for connections\n",
    "                    c = driver.find_elements_by_xpath('//ul[@class = \"pv-top-card--list pv-top-card--list-bullet mt1\"]/li[@class = \"inline-block\"]')\n",
    "                    founder_.connections = (c[0].text)\n",
    "                    ########\n",
    "                    #Extract founder location\n",
    "                    loc_ = driver.find_elements_by_xpath('//li[@class = \"t-16 t-black t-normal inline-block\"]')\n",
    "                    founder_.location = (loc_[0].text)\n",
    "                    ###########################################################\n",
    "                    # Extracts degree information (formatted as a list of items)\n",
    "                    schools = driver.find_elements_by_xpath('//div[@class=\"pv-entity__degree-info\"]')\n",
    "                    for school in schools:\n",
    "                        school_ = school.text.split('\\n')\n",
    "                        # The school is formatted as a list [School Name,'Degree Name',Degree Name,'Field of Study',FOS]\n",
    "                        try:\n",
    "                            educ_ = Education(school_[0])\n",
    "                            try:\n",
    "                                educ_.degree = school_[2]\n",
    "                                educ_.field = school_[4]\n",
    "                            except:\n",
    "                                pass\n",
    "                            # Appends the temporary education object to the founder\n",
    "                            founder_.education.append(educ_)\n",
    "                        except:\n",
    "                            print(\"No schools\")\n",
    "                            pass\n",
    "\n",
    "                    ###############################################################    \n",
    "                    # Extracts experience information (formatted as a list of items)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight/3);\")\n",
    "                    sleep(1.0)\n",
    "                    experiences = driver.find_elements_by_xpath('//a[@data-control-name=\"background_details_company\"]')\n",
    "                    for exp in experiences:\n",
    "                        exp_lst = exp.text.split('\\n')\n",
    "                        # The exp_ is formatted as [title, 'companyname', companyname, 'datesemployed', datesemployed, ..]\n",
    "                        try:\n",
    "                            if exp_lst[0] == 'Company Name':\n",
    "                                exp_ = Experience(exp_lst[1])\n",
    "                                founder_.experience.append(exp_)\n",
    "                            else:\n",
    "                                exp_ = Experience(exp_lst[2])\n",
    "                                try:\n",
    "                                    exp_.title = exp_lst[0]\n",
    "                                    exp_.dates = exp_lst[4]\n",
    "                                    founder_.experience.append(exp_)\n",
    "                                except:\n",
    "                                    founder_.experience.append(exp_)\n",
    "                        except:\n",
    "                            print(\"No experience\")\n",
    "                            pass\n",
    "                    # Appends the temporary founder object to the company\n",
    "                    company_.founders.append(founder_)\n",
    "                    sleep(1.0)\n",
    "                else:\n",
    "                    founder_ = Founder(founder)\n",
    "                    company_.founders.append(founder_)\n",
    "                    print(\"{} not found for {}\".format(company_.name, founder_.name))\n",
    "                    sleep(1.0)\n",
    "            except:\n",
    "                print(\"{} not found for\".format(company_.name, founder))\n",
    "    except:\n",
    "        print(\"Structural Error\")\n",
    "    # Adds the company to the company_data dictionary\n",
    "    company_data[company_.name] = company_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "101\n",
      "102\n",
      "DataGrail not found for\n",
      "103\n",
      "104\n",
      "105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "107\n",
      "Rivery.io not found for\n",
      "Rivery.io not found for\n",
      "Rivery.io not found for\n",
      "108\n",
      "PollyEx not found for\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "Hyperlex not found for\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "VoiceSell, Inc. not found for\n",
      "VoiceSell, Inc. not found for\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "Stonly not found for\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "Payhawk not found for\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "Athlane not found for\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "Reibus International not found for\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "# Stores data for a single company in company_data\n",
    "for i in range(100,200):\n",
    "    print(i)\n",
    "    if i%5 == 0:\n",
    "        sleep(5.0)\n",
    "    scrapeLI(df1.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapeLI(df1.iloc[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData(company_data, 'data200.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in company_data.keys():\n",
    "    for founder in company_data[key].founders:\n",
    "        if not founder.education:\n",
    "            print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['Organization Name'] == \"Opora\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data['ProdPerfect'].founders[1].location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = loadData('data200.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = {}\n",
    "fields = {}\n",
    "companynames = {}\n",
    "jobtitle = {}\n",
    "\n",
    "for key in loaded.keys():\n",
    "    for founder in loaded[key]['founders']:\n",
    "        if founder['education']:\n",
    "            for educ_ in founder['education']:\n",
    "                school = educ_['school'].lower()\n",
    "                for word in school.split(' '):\n",
    "                    if word in schools:\n",
    "                        schools[word] += 1\n",
    "                    else:\n",
    "                        schools[word] = 1\n",
    "                if educ_['field']:\n",
    "                    field = educ_['field'].lower()\n",
    "                    for word in field.split(' '):\n",
    "                        if word in fields:\n",
    "                            fields[word] += 1\n",
    "                        else:\n",
    "                            fields[word] = 1\n",
    "        if founder['experience']:\n",
    "            for exp_ in founder['experience']:\n",
    "                companyName = exp_['companyName'].lower()\n",
    "                for word in companyName.split(' '):\n",
    "                    if word in companynames:\n",
    "                        companynames[word] += 1\n",
    "                    else:\n",
    "                        companynames[word] = 1\n",
    "                if exp_['title']:\n",
    "                    title = exp_['title'].lower()\n",
    "                    if title in jobtitle:\n",
    "                        jobtitle[title] += 1\n",
    "                    else:\n",
    "                        jobtitle[title] = 1\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Saves the extracted data to a CSV'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schools = pd.DataFrame.from_dict(schools, orient='index', columns=['freq'])\n",
    "df_schools.sort_values(['freq'], ascending=False).to_csv('schools.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fields = pd.DataFrame.from_dict(fields, orient='index', columns=['freq'])\n",
    "df_fields.sort_values(['freq'], ascending=False).to_csv('fields.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compnames = pd.DataFrame.from_dict(companynames, orient='index', columns=['freq'])\n",
    "df_compnames.sort_values(['freq'], ascending=False).to_csv('companynames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = pd.DataFrame.from_dict(jobtitle, orient='index', columns=['freq'])\n",
    "df_titles.sort_values(['freq'], ascending=False).to_csv('titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
